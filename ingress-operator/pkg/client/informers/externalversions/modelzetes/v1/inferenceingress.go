/*
Copyright 2023 TensorChord Inc.

Licensed under the MIT license. See LICENSE file in the project root for full license information.
*/

// Code generated by informer-gen. DO NOT EDIT.

package v1

import (
	"context"
	time "time"

	modelzetesv1 "github.com/tensorchord/openmodelz/ingress-operator/pkg/apis/modelzetes/v1"
	versioned "github.com/tensorchord/openmodelz/ingress-operator/pkg/client/clientset/versioned"
	internalinterfaces "github.com/tensorchord/openmodelz/ingress-operator/pkg/client/informers/externalversions/internalinterfaces"
	v1 "github.com/tensorchord/openmodelz/ingress-operator/pkg/client/listers/modelzetes/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	runtime "k8s.io/apimachinery/pkg/runtime"
	watch "k8s.io/apimachinery/pkg/watch"
	cache "k8s.io/client-go/tools/cache"
)

// InferenceIngressInformer provides access to a shared informer and lister for
// InferenceIngresses.
type InferenceIngressInformer interface {
	Informer() cache.SharedIndexInformer
	Lister() v1.InferenceIngressLister
}

type inferenceIngressInformer struct {
	factory          internalinterfaces.SharedInformerFactory
	tweakListOptions internalinterfaces.TweakListOptionsFunc
	namespace        string
}

// NewInferenceIngressInformer constructs a new informer for InferenceIngress type.
// Always prefer using an informer factory to get a shared informer instead of getting an independent
// one. This reduces memory footprint and number of connections to the server.
func NewInferenceIngressInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers) cache.SharedIndexInformer {
	return NewFilteredInferenceIngressInformer(client, namespace, resyncPeriod, indexers, nil)
}

// NewFilteredInferenceIngressInformer constructs a new informer for InferenceIngress type.
// Always prefer using an informer factory to get a shared informer instead of getting an independent
// one. This reduces memory footprint and number of connections to the server.
func NewFilteredInferenceIngressInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {
	return cache.NewSharedIndexInformer(
		&cache.ListWatch{
			ListFunc: func(options metav1.ListOptions) (runtime.Object, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.TensorchordV1().InferenceIngresses(namespace).List(context.TODO(), options)
			},
			WatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.TensorchordV1().InferenceIngresses(namespace).Watch(context.TODO(), options)
			},
		},
		&modelzetesv1.InferenceIngress{},
		resyncPeriod,
		indexers,
	)
}

func (f *inferenceIngressInformer) defaultInformer(client versioned.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer {
	return NewFilteredInferenceIngressInformer(client, f.namespace, resyncPeriod, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc}, f.tweakListOptions)
}

func (f *inferenceIngressInformer) Informer() cache.SharedIndexInformer {
	return f.factory.InformerFor(&modelzetesv1.InferenceIngress{}, f.defaultInformer)
}

func (f *inferenceIngressInformer) Lister() v1.InferenceIngressLister {
	return v1.NewInferenceIngressLister(f.Informer().GetIndexer())
}
